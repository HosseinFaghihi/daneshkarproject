{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "extracting data from a zip file\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rar_file_path = r\"F:\\daneshkar\\project1\\202405.zip\" \n",
    "output_folder = 'extracted_rar_files'  \n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(rar_file_path, 'r') as rf:\n",
    "    rf.extractall(output_folder)\n",
    "\n",
    "\n",
    "for filename in os.listdir(output_folder):\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f'extracting file {filename} ')\n",
    "        with zipfile.ZipFile(file_path, 'r') as rf_inner:\n",
    "            rf_inner.extractall(os.path.join(output_folder, filename[:-4])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read parquet files and create a dataframe and save them in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_and_group_parquet_files(base_folder, start_date, end_date, folders_in_row):\n",
    "    data_frames = defaultdict(list)\n",
    "    group_names = [\n",
    "        'home_team_score',\n",
    "        'home_team',\n",
    "        'away_team',\n",
    "        'away_team_score',\n",
    "        'event',\n",
    "        'round',\n",
    "        'season',\n",
    "        'time',\n",
    "        'tournament',\n",
    "        'venue',\n",
    "        'odds',\n",
    "        'pbp',\n",
    "        'statistics',\n",
    "        'power',\n",
    "        'votes'\n",
    "    ]\n",
    "\n",
    "    # Regular expressions for away_team and away_team_score\n",
    "    away_team_pattern = re.compile(r'^away_team_')\n",
    "    away_team_score_pattern = re.compile(r'^away_team_score_')\n",
    "\n",
    "    for date in range(start_date, end_date + 1):\n",
    "        for folder in folders_in_row:\n",
    "            date_folder = os.path.join(base_folder, str(date), 'data', 'raw', folder)\n",
    "            print(f'Reading folder: {date_folder}')  # Monitor the current folder\n",
    "            if os.path.isdir(date_folder):\n",
    "                for file_name in os.listdir(date_folder):\n",
    "                    if file_name.endswith('.parquet'):\n",
    "                        matched_group = None\n",
    "                        # Check each group name if the filename starts with it\n",
    "                        if away_team_score_pattern.match(file_name):\n",
    "                            matched_group = 'away_team_score'\n",
    "                        elif away_team_pattern.match(file_name):\n",
    "                            matched_group = 'away_team'\n",
    "                        else:\n",
    "                            # Simple string matching for other group names\n",
    "                            for group_name in group_names:\n",
    "                                if file_name.startswith(group_name + '_'):\n",
    "                                    matched_group = group_name\n",
    "                                    break\n",
    "\n",
    "                        if matched_group:\n",
    "                            file_path = os.path.join(date_folder, file_name)\n",
    "                            df = pd.read_parquet(file_path)\n",
    "                            data_frames[matched_group].append(df)\n",
    "\n",
    "    # Concatenate DataFrames in each group and save to CSV\n",
    "    grouped_data_frames = {}\n",
    "    for group, dfs in data_frames.items():\n",
    "        if dfs:  # Check if the list of DataFrames is not empty\n",
    "            concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "            grouped_data_frames[group] = concatenated_df\n",
    "            # Save DataFrame to CSV\n",
    "            csv_file_path = os.path.join(base_folder, f'{group}.csv')\n",
    "            concatenated_df.to_csv(csv_file_path, index=False)\n",
    "            print(f'Saved {group} DataFrame to {csv_file_path}')\n",
    "\n",
    "    return grouped_data_frames\n",
    "\n",
    "# Example usage\n",
    "base_folder = r'F:\\daneshkar\\project1\\extracted_rar_files'\n",
    "start_date = 20240501\n",
    "end_date = 20240531\n",
    "folders_in_row = (\n",
    "    'raw_match_parquet',\n",
    "    'raw_odds_parquet',\n",
    "    'raw_point_by_point_parquet',\n",
    "    'raw_statistics_parquet',\n",
    "    'raw_tennis_power_parquet',\n",
    "    'raw_votes_parquet'\n",
    ")\n",
    "\n",
    "grouped_data_frames = read_and_group_parquet_files(base_folder, start_date, end_date, folders_in_row)\n",
    "\n",
    "# Display the groups and their DataFrames\n",
    "for group_name, df in grouped_data_frames.items():\n",
    "    print(f'Group: {group_name}')\n",
    "    # print(df.head())  # Print the first few rows of each DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and group names\n",
    "base_folder = r'F:\\daneshkar\\project1\\extracted_rar_files'\n",
    "group_names = [\n",
    "    'home_team_score',\n",
    "    'home_team',\n",
    "    'away_team',\n",
    "    'away_team_score',\n",
    "    'event',\n",
    "    'round',\n",
    "    'season',\n",
    "    'time',\n",
    "    'tournament',\n",
    "    'venue',\n",
    "    'odds',\n",
    "    'pbp',\n",
    "    'statistics',\n",
    "    'power',\n",
    "    'votes'\n",
    "]\n",
    "\n",
    "# Initialize a dictionary to store the DataFrames\n",
    "grouped_data_frames = {}\n",
    "\n",
    "# Read each CSV file into a DataFrame and store it in the dictionary\n",
    "for group_name in group_names:\n",
    "    csv_file_path = os.path.join(base_folder, f'{group_name}.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        grouped_data_frames[group_name] = df\n",
    "        print(f'Successfully read {group_name}.csv')\n",
    "    else:\n",
    "        print(f'File {group_name}.csv not found')\n",
    "\n",
    "# Display the DataFrames (or perform further operations)\n",
    "for group_name, df in grouped_data_frames.items():\n",
    "    print(f'Group: {group_name}')\n",
    "    # print(df.head())  # Print the first few rows of each DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the shape of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of each DataFrame\n",
    "for group_name, df in grouped_data_frames.items():\n",
    "    print(f'Group: {group_name}, Shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many tennis players are included in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_players(grouped_data_frames):\n",
    "    player_ids = set()\n",
    "    \n",
    "    # Extract player IDs from home team info\n",
    "    if 'home_team' in grouped_data_frames:\n",
    "        home_team_df = grouped_data_frames['home_team']\n",
    "        if 'player_id' in home_team_df.columns:\n",
    "            player_ids.update(home_team_df['player_id'].unique())\n",
    "    \n",
    "    # Extract player IDs from away team info\n",
    "    if 'away_team' in grouped_data_frames:\n",
    "        away_team_df = grouped_data_frames['away_team']\n",
    "        if 'player_id' in away_team_df.columns:\n",
    "            player_ids.update(away_team_df['player_id'].unique())\n",
    "    \n",
    "    # Return the count of unique player IDs\n",
    "    return len(player_ids)\n",
    "\n",
    "# Count unique players\n",
    "num_unique_players = count_unique_players(grouped_data_frames)\n",
    "print(f'The number of unique tennis players in the dataset is: {num_unique_players}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "otherway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = grouped_data_frames['event']\n",
    "home_team = grouped_data_frames['home_team']\n",
    "away_team = grouped_data_frames['away_team']\n",
    "\n",
    "# Combine home and away team info into one DataFrame\n",
    "players_info = pd.concat([\n",
    "    home_team[['player_id', 'full_name']],\n",
    "    away_team[['player_id', 'full_name']]\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "number_of_tennis_players=len(players_info)\n",
    "\n",
    "print(f'The number of unique tennis players in the dataset is: {number_of_tennis_players}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "2.What is the average height of the players?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_away_team = grouped_data_frames['away_team'].dropna(subset=['gender'])\n",
    "df_cleaned_home_team = grouped_data_frames['home_team'].dropna(subset=['gender'])\n",
    "#We remove the rows that have missing values in the gender column.\n",
    "\n",
    "df_concat_gender=pd.concat([df_cleaned_home_team[['player_id','full_name','gender','height']],df_cleaned_away_team[['player_id','full_name','gender','height']]]).drop_duplicates().reset_index(drop=True)\n",
    "mean_height_male_with_null = df_concat_gender[df_concat_gender['gender'] == 'M']['height'].mean()\n",
    "mean_height_female_with_null = df_concat_gender[df_concat_gender['gender'] == 'F']['height'].mean()\n",
    "num_missing = df_concat_gender['gender'].isna().sum()\n",
    "def fill_height(row):\n",
    "    if pd.isna(row['height']):\n",
    "        if row['gender'] == 'M':\n",
    "            return mean_height_male_with_null\n",
    "        elif row['gender'] == 'F':\n",
    "            return mean_height_female_with_null\n",
    "    return row['height']\n",
    "df_concat_gender['height'] = df_concat_gender.apply(fill_height, axis=1)\n",
    "mean_height_male = df_concat_gender[df_concat_gender['gender'] == 'M']['height'].mean()\n",
    "mean_height_female = df_concat_gender[df_concat_gender['gender'] == 'F']['height'].mean()\n",
    "mean_height_players=df_concat_gender['height'].mean()\n",
    "print(f'The average height of female players is {mean_height_female} ')\n",
    "print(f'The average height of male players is {mean_height_male}')\n",
    "print(f'The average height of players is {mean_height_players}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Which player has the highest number of wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming grouped_data_frames is your dictionary containing all the dataframes\n",
    "event = grouped_data_frames['event']\n",
    "home_team = grouped_data_frames['home_team']\n",
    "away_team = grouped_data_frames['away_team']\n",
    "\n",
    "# Combine home and away team info into one DataFrame\n",
    "players_info = pd.concat([\n",
    "    home_team[['player_id', 'full_name']],\n",
    "    away_team[['player_id', 'full_name']]\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Merge event DataFrame with home_team and away_team DataFrames to get player IDs\n",
    "event = event.merge(home_team[['match_id', 'player_id']], left_on='match_id', right_on='match_id', how='left', suffixes=('', '_home'))\n",
    "event = event.rename(columns={'player_id': 'player_id_home'})  # Rename the merged column from home_team\n",
    "event = event.merge(away_team[['match_id', 'player_id']], left_on='match_id', right_on='match_id', how='left', suffixes=('', '_away'))\n",
    "event = event.rename(columns={'player_id': 'player_id_away'})  # Rename the merged column from away_team\n",
    "\n",
    "\n",
    "\n",
    "# Map winner_code to actual player IDs\n",
    "def get_winner_player_id(row):\n",
    "    if row['winner_code'] == 1:\n",
    "        return row['player_id_home']\n",
    "    elif row['winner_code'] == 2:\n",
    "        return row['player_id_away']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Check if 'player_id_home' and 'player_id_away' columns are present\n",
    "if 'player_id_home' in event.columns and 'player_id_away' in event.columns:\n",
    "    event['winner_player_id'] = event.apply(get_winner_player_id, axis=1)\n",
    "else:\n",
    "    raise KeyError(\"Expected columns 'player_id_home' and 'player_id_away' not found in the event DataFrame.\")\n",
    "\n",
    "# Count the number of wins for each player using groupby\n",
    "win_counts = event.groupby('winner_player_id').size().reset_index(name='win_count').rename(columns={'winner_player_id': 'player_id'})\n",
    "\n",
    "print(\"Win Counts DataFrame:\")\n",
    "print(win_counts)\n",
    "\n",
    "# Merge win counts with player information\n",
    "player_wins = pd.merge(win_counts, players_info, on='player_id', how='left')\n",
    "\n",
    "print(\"Player Wins DataFrame:\")\n",
    "print(player_wins)\n",
    "\n",
    "# Find the player with the highest number of wins\n",
    "if not player_wins.empty:\n",
    "    top_player = player_wins.loc[player_wins['win_count'].idxmax()]\n",
    "    print(f\"Player with the highest number of wins: {top_player['full_name']} with {top_player['win_count']} wins\")\n",
    "else:\n",
    "    print(\"No wins found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "4.What is the longest match recorded in terms of duration?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time=grouped_data_frames['time']\n",
    "df_time[df_time['current_period_start_timestamp'].isna()]\n",
    "df_time['datetime'] = pd.to_datetime(df_time['current_period_start_timestamp'], unit='s')\n",
    "columns_to_check = df_time.columns[1:6]\n",
    "df_time_filtered = df_time.dropna(subset=columns_to_check, how='all')\n",
    "match_recorded_column_data = df_time.iloc[:, 1:6].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "insert match_recorded to table of time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time=df_time.insert(loc=6, column='Match recorded', value=match_recorded_column_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = match_recorded_column_data <= 39600\n",
    "#The longest tennis set lasted 11 hours, so we don't consider data beyond this timeframe.\n",
    "if condition.any():\n",
    "   \n",
    "    max_row = df_time.loc[condition].iloc[:, 0:5].sum(axis=1).idxmax()\n",
    "    df_time = df_time.drop(columns=df_time.columns[1:6])\n",
    "    result_row = df_time.loc[max_row]\n",
    "\n",
    "print(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.How many sets are typically played in a tennis match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team_score_df = grouped_data_frames['home_team_score']\n",
    "# Select columns period_1 to period_5\n",
    "period_columns = ['period_1', 'period_2', 'period_3', 'period_4', 'period_5']\n",
    "\n",
    "# Count non-null values across rows (axis=1)\n",
    "home_team_score_df['filled_columns_count'] = home_team_score_df[period_columns].count(axis=1)\n",
    "\n",
    "# Find the mode of filled_sets_count\n",
    "mode_sets_count = home_team_score_df['filled_columns_count'].mode().values[0]\n",
    "\n",
    "print(f\"Typically, {mode_sets_count} sets are played in a tennis match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "6.Which country has produced the most successful tennis players?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_rank=pd.concat([grouped_data_frames['home_team'],grouped_data_frames['away_team']])\n",
    "df_rank = df_all_rank[(df_all_rank['current_rank'] <= 20) ]\n",
    "df_rank_w=df_rank.drop(columns=['match_id','user_count','current_prize','total_prize'])\n",
    "df_rank_duplicates=df_rank_w.drop_duplicates()\n",
    "sorted_df = df_rank_duplicates.sort_values(by='current_rank', ascending=True)\n",
    "\n",
    "df_unique_rank =  sorted_df.groupby('name').first().reset_index()\n",
    "\n",
    "value_counts=df_unique_rank['country'].value_counts()\n",
    "value_counts.plot(kind='bar',color='green')\n",
    "plt.yticks(range(int(value_counts.max()) + 1))\n",
    "plt.show()\n",
    "max_index = value_counts.idxmax()\n",
    "countries_with_max_value = value_counts[value_counts == value_counts[max_index]].index.tolist()\n",
    "\n",
    "print(f\"{', '.join(map(str, countries_with_max_value[:-1]))} , {countries_with_max_value[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.What is the average number of aces per match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we check the symmetry of data by the histogram of data to chose between mean and median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "statistics_df = grouped_data_frames['statistics']\n",
    "\n",
    "# Filter statistics dataframe for rows where statistic_name is 'aces' and period is 'ALL'\n",
    "aces_df = statistics_df[(statistics_df['statistic_name'] == 'aces') & (statistics_df['period'] == 'ALL')].copy()\n",
    "\n",
    "# Convert 'home_stat' and 'away_stat' to numeric if they are not already\n",
    "aces_df.loc[:, 'home_stat'] = pd.to_numeric(aces_df['home_stat'], errors='coerce')\n",
    "aces_df.loc[:, 'away_stat'] = pd.to_numeric(aces_df['away_stat'], errors='coerce')\n",
    "\n",
    "# Calculate the total_stat as the sum of home_stat and away_stat\n",
    "aces_df['total_stat'] = aces_df['home_stat'] + aces_df['away_stat']\n",
    "\n",
    "# Plot histogram to check distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(aces_df['total_stat'].dropna(), bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.title('Histogram of Total Stat for \"aces\" and Period=\"ALL\"', fontsize=14)\n",
    "plt.xlabel('Total Stat', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and median\n",
    "mean_total_stat = aces_df['total_stat'].mean()\n",
    "median_total_stat = aces_df['total_stat'].median()\n",
    "\n",
    "# Print mean and median\n",
    "print(f\"Mean of total_stat: {mean_total_stat:.2f}\")\n",
    "print(f\"Median of total_stat: {median_total_stat:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boxplot can help identify skewness and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(aces_df['total_stat'], vert=False, patch_artist=True, widths=0.7)\n",
    "plt.title('Boxplot of total_stat for \"aces\" and period=\"ALL\"', fontsize=14)\n",
    "plt.xlabel('Total Stat', fontsize=12)\n",
    "plt.yticks([], [])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the average number of aces per match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of total_stat\n",
    "median_total_stat = aces_df['total_stat'].median()\n",
    "\n",
    "# Print the mean of total_stat\n",
    "print(f\"the average number of aces per match is: {median_total_stat:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the matches that have more that 13 ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aces_df[['match_id','total_stat']].loc[aces_df['total_stat']>13].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "8.Is there a difference in the number of double faults based on gender?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistics=grouped_data_frames['statistics']\n",
    "\n",
    "df_away_team=grouped_data_frames['away_team'][['match_id','full_name','gender']]\n",
    "df_home_team=grouped_data_frames['home_team'][['match_id','full_name','gender']]\n",
    "\n",
    "df_concat_team=pd.concat([df_away_team,df_home_team])\n",
    "\n",
    "filtered_df_statistics = df_statistics[df_statistics['statistic_name'] =='double_faults' ][['match_id']]\n",
    "grouped_filtered_df_statistics = filtered_df_statistics.groupby('match_id').size().reset_index(name='Count')\n",
    "merged_df = pd.merge(grouped_filtered_df_statistics, df_concat_team, on='match_id', how='inner')\n",
    "merged_df_deduplicated_by_columns = merged_df.drop_duplicates(subset=['match_id']).reset_index(drop=True)\n",
    "gender_count_sum = merged_df_deduplicated_by_columns.groupby('gender')['Count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Which player has won the most tournaments in a single month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming grouped_data_frames is your dictionary containing all the dataframes\n",
    "event_df = grouped_data_frames['event']\n",
    "home_team_df = grouped_data_frames['home_team']\n",
    "away_team_df = grouped_data_frames['away_team']\n",
    "tournament_df = grouped_data_frames['tournament']\n",
    "\n",
    "# Merge dataframes to get the necessary information\n",
    "merged_df = event_df.merge(home_team_df[['match_id', 'player_id', 'name']], on='match_id', suffixes=('_home', '_away'))\n",
    "merged_df = merged_df.merge(away_team_df[['match_id', 'player_id']], on='match_id', suffixes=('', '_away'))\n",
    "merged_df = merged_df.merge(tournament_df[['match_id', 'tournament_id', 'tournament_name']], on='match_id')\n",
    "\n",
    "# Determine the winner's player_id for each match\n",
    "merged_df['winner_player_id'] = merged_df.apply(\n",
    "    lambda row: row['player_id'] if row['winner_code'] == 1 else row['player_id_away'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Count the number of tournaments won by each player\n",
    "tournament_wins = merged_df.groupby('winner_player_id').size().reset_index(name='tournament_wins')\n",
    "\n",
    "# Find the player with the maximum number of tournament wins\n",
    "max_wins = tournament_wins.loc[tournament_wins['tournament_wins'].idxmax()]\n",
    "\n",
    "# Get the player's name\n",
    "player_info = home_team_df[['player_id', 'name']].drop_duplicates().set_index('player_id')\n",
    "max_wins_player_name = player_info.loc[max_wins['winner_player_id'], 'name']\n",
    "max_wins_count = max_wins['tournament_wins']\n",
    "\n",
    "print(f\"Player {max_wins_player_name} won the most tournaments ({max_wins_count}) in the given month.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "10.Is there a correlation between a player's height and their ranking?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_team=pd.concat([grouped_data_frames['away_team'],grouped_data_frames['home_team']])\n",
    "df_concat_team=df_concat_team.drop(columns=['match_id','user_count','current_prize','total_prize'])\n",
    "df_concat_team=df_concat_team.drop_duplicates()\n",
    "df_concat_team=df_concat_team.groupby('name').first().reset_index()\n",
    "correlation = df_concat_team['height'].corr(df_concat_team['current_rank'])\n",
    "if correlation >= 0.7 or correlation <= -0.7:\n",
    "    correlation_category = \"Strong correlation\"\n",
    "elif 0.4 <= correlation < 0.7 or -0.4 >= correlation > -0.7:\n",
    "    correlation_category = \"Moderate correlation\"\n",
    "elif 0.1 <= correlation < 0.4 or -0.1 >= correlation > -0.4:\n",
    "    correlation_category = \"Weak correlation\"\n",
    "else:\n",
    "    correlation_category = \"Very weak or no correlation\"\n",
    "\n",
    "\n",
    "print(f\"The correlation between Column1 and Column2 is: {correlation}\")\n",
    "print(f\"This correlation is categorized as: {correlation_category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.What is the average duration of matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_df = grouped_data_frames['time']\n",
    "\n",
    "# Ensure all period columns are treated as numeric, and NaNs are handled\n",
    "time_df = time_df[['match_id', 'period_1', 'period_2', 'period_3', 'period_4', 'period_5']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Calculate the total duration for each match by summing the periods\n",
    "time_df['total_duration'] = time_df[['period_1', 'period_2', 'period_3', 'period_4', 'period_5']].sum(axis=1, skipna=True)\n",
    "\n",
    "# Calculate the average duration\n",
    "average_duration = time_df['total_duration'].mean()\n",
    "\n",
    "print(f\"The average duration of matches is {average_duration/60} minutes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "12-What is the average number of games per set in men's matches compared to women's matches?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nan_count = grouped_data_frames['power']['set_num'].isna().sum()\n",
    "#check for null value\n",
    "df_team_without_filter=pd.concat([grouped_data_frames['away_team'],grouped_data_frames['home_team']])[['gender','match_id']]\n",
    "condition = df_team_without_filter['gender'].notna()\n",
    "df_team_with_filter=df_team_without_filter[condition]\n",
    "df_merge_team_power=pd.merge(df_team_with_filter,grouped_data_frames['power'][['match_id','set_num','game_num']] , on='match_id', how='inner')\n",
    "count_set=len(df_merge_team_power['set_num'].unique())\n",
    "grouped = df_merge_team_power.groupby('gender')['game_num'].sum()\n",
    "\n",
    "result = grouped / count_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.What is the distribution of left-handed versus right-handed players?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming grouped_data_frames is your dictionary containing all the dataframes\n",
    "home_team_df = grouped_data_frames['home_team']\n",
    "away_team_df = grouped_data_frames['away_team']\n",
    "\n",
    "# Combine the relevant data to get a comprehensive list of players\n",
    "combined_players_df = pd.concat([home_team_df[['player_id', 'plays']], away_team_df[['player_id', 'plays']]])\n",
    "\n",
    "# Drop duplicate players if they appear in both home_team and away_team\n",
    "players_df = combined_players_df.drop_duplicates(subset=['player_id']).copy()\n",
    "\n",
    "# Check the unique values in the 'plays' column\n",
    "unique_plays = players_df['plays'].unique()\n",
    "print(\"Unique values in 'plays' column:\")\n",
    "print(unique_plays)\n",
    "\n",
    "# Check for missing or NaN values\n",
    "missing_plays = players_df['plays'].isna().sum()\n",
    "print(f\"Number of missing or NaN values in 'plays' column: {missing_plays}\")\n",
    "\n",
    "# Fill or handle missing values (assuming 'unknown' for missing entries)\n",
    "players_df['plays'] = players_df['plays'].fillna('unknown')\n",
    "\n",
    "# Calculate the distribution of left-handed vs right-handed players\n",
    "handedness_distribution = players_df['plays'].value_counts()\n",
    "\n",
    "# Print the distribution\n",
    "print(\"Distribution of left-handed vs right-handed players:\")\n",
    "print(handedness_distribution)\n",
    "\n",
    "# Plot the distribution using a pie chart\n",
    "explode = [0.1 if handedness == \"ambidextrous\" else 0 for handedness in handedness_distribution.index]\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']  # Optional: Define custom colors\n",
    "\n",
    "handedness_distribution.plot(kind='pie', autopct='%1.1f%%', startangle=90, figsize=(8, 8), legend=True, explode=explode, colors=colors)\n",
    "plt.title('Distribution of Left-handed vs Right-handed Players')\n",
    "plt.ylabel('')  # Hide the y-label\n",
    "plt.legend(title='Handedness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "14.What is the most common type of surface used in tournaments?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data_frames['tournament']['ground_type'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.How many distinct countries are represented in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "home_team_df = grouped_data_frames['home_team']\n",
    "away_team_df = grouped_data_frames['away_team']\n",
    "\n",
    "# Combine the country data from both home_team and away_team dataframes\n",
    "countries = pd.concat([home_team_df['country'], away_team_df['country']])\n",
    "\n",
    "# Find the number of distinct countries\n",
    "distinct_countries = countries.nunique()\n",
    "\n",
    "print(f\"Number of distinct countries represented in the dataset: {distinct_countries}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "16.What is the most common type of surface used in tournaments?\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffi=grouped_data_frames['pbp']\n",
    "last_row_per_id = dffi.groupby('match_id').last().reset_index()\n",
    "def determine_winner(row):\n",
    "    home_has_A = 'A' in str(row['home_point'])\n",
    "    away_has_A = 'A' in str(row['away_point'])\n",
    "\n",
    "    if home_has_A and not away_has_A:\n",
    "        return 0  \n",
    "    elif away_has_A and not home_has_A:\n",
    "        return 1  \n",
    "    elif '40' in [row['home_point'], row['away_point']]:\n",
    "        return 0 if row['home_point'] == '40' else 1  \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "last_row_per_id['Winner'] = last_row_per_id.apply(determine_winner, axis=1)\n",
    "df_home_new=grouped_data_frames['home_team']\n",
    "df_home_new['h/a']=0\n",
    "df_away_new=grouped_data_frames['away_team']\n",
    "df_away_new['h/a']=1\n",
    "df_home_away=pd.concat([df_home_new,df_away_new])\n",
    "df_merge_team_pbp=pd.merge(df_home_away,last_row_per_id[['Winner','match_id']] ,on='match_id',how='inner')\n",
    "df_merge_team_pbp=df_merge_team_pbp[['match_id','name', 'gender','current_rank','h/a','Winner']].sort_values(by='match_id')\n",
    "grouped = df_merge_team_pbp.groupby('match_id').filter(lambda x: (x['current_rank'] <= 10).any()).reset_index(drop=True)\n",
    "filterede_df = grouped[(grouped['h/a'] == grouped['Winner']) & (grouped['current_rank'] > 10)]\n",
    "count=grouped[(grouped['current_rank'] > 10)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "count_df1 = filterede_df['name'].value_counts().reset_index()\n",
    "count_df1.columns = ['name', 'wincounts']\n",
    "\n",
    "count_df2 = count['name'].value_counts().reset_index()\n",
    "count_df2.columns=['name','matchcount']\n",
    "\n",
    "\n",
    "df_count_all=pd.merge(count_df1,count_df2,on='name',how='inner').reset_index(drop=True)\n",
    "df_count_all['win percentage']=df_count_all['wincounts']*100/df_count_all['matchcount']\n",
    "df_count_all=df_count_all.sort_values(by='win percentage',ascending=False)\n",
    "df_count_all[df_count_all['win percentage']==100].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.What is the average number of breaks of serve per match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming grouped_data_frames is your dictionary containing all the dataframes\n",
    "home_team_score_df = grouped_data_frames['home_team_score']\n",
    "\n",
    "# Select columns period_1_tie_break to period_5_tie_break\n",
    "period_tie_break_columns = ['period_1_tie_break', 'period_2_tie_break', 'period_3_tie_break', 'period_4_tie_break', 'period_5_tie_break']\n",
    "\n",
    "# Count non-null values across rows (axis=1)\n",
    "home_team_score_df['filled_columns_count'] = home_team_score_df[period_tie_break_columns].count(axis=1)\n",
    "\n",
    "# Find the median of filled_columns_count\n",
    "median_sets_count = home_team_score_df['filled_columns_count'].median()\n",
    "\n",
    "print(f\"Typically, the median number of sets played in a tennis match is {median_sets_count}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see better :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot for the number of break in tennis matches\n",
    "sets_count = home_team_score_df['filled_columns_count'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sets_count.plot(kind='bar')\n",
    "plt.title('Bar Plot of Number of breaks in Tennis Matches')\n",
    "plt.xlabel('Number of Sets')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
