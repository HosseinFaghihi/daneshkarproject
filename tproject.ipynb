{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "extracting data from a zip file\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rar_file_path = r\"F:\\daneshkar\\project1\\202405.zip\" \n",
    "output_folder = 'extracted_rar_files'  \n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(rar_file_path, 'r') as rf:\n",
    "    rf.extractall(output_folder)\n",
    "\n",
    "\n",
    "for filename in os.listdir(output_folder):\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f'extracting file {filename} ')\n",
    "        with zipfile.ZipFile(file_path, 'r') as rf_inner:\n",
    "            rf_inner.extractall(os.path.join(output_folder, filename[:-4])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read parquet files and create a dataframe and save them in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_and_group_parquet_files(base_folder, start_date, end_date, folders_in_row):\n",
    "    data_frames = defaultdict(list)\n",
    "    group_names = [\n",
    "        'home_team_score',\n",
    "        'home_team',\n",
    "        'away_team',\n",
    "        'away_team_score',\n",
    "        'event',\n",
    "        'round',\n",
    "        'season',\n",
    "        'time',\n",
    "        'tournament',\n",
    "        'venue',\n",
    "        'odds',\n",
    "        'pbp',\n",
    "        'statistics',\n",
    "        'power',\n",
    "        'votes'\n",
    "    ]\n",
    "\n",
    "    # Regular expressions for away_team and away_team_score\n",
    "    away_team_pattern = re.compile(r'^away_team_')\n",
    "    away_team_score_pattern = re.compile(r'^away_team_score_')\n",
    "\n",
    "    for date in range(start_date, end_date + 1):\n",
    "        for folder in folders_in_row:\n",
    "            date_folder = os.path.join(base_folder, str(date), 'data', 'raw', folder)\n",
    "            print(f'Reading folder: {date_folder}')  # Monitor the current folder\n",
    "            if os.path.isdir(date_folder):\n",
    "                for file_name in os.listdir(date_folder):\n",
    "                    if file_name.endswith('.parquet'):\n",
    "                        matched_group = None\n",
    "                        # Check each group name if the filename starts with it\n",
    "                        if away_team_score_pattern.match(file_name):\n",
    "                            matched_group = 'away_team_score'\n",
    "                        elif away_team_pattern.match(file_name):\n",
    "                            matched_group = 'away_team'\n",
    "                        else:\n",
    "                            # Simple string matching for other group names\n",
    "                            for group_name in group_names:\n",
    "                                if file_name.startswith(group_name + '_'):\n",
    "                                    matched_group = group_name\n",
    "                                    break\n",
    "\n",
    "                        if matched_group:\n",
    "                            file_path = os.path.join(date_folder, file_name)\n",
    "                            df = pd.read_parquet(file_path)\n",
    "                            data_frames[matched_group].append(df)\n",
    "\n",
    "    # Concatenate DataFrames in each group and save to CSV\n",
    "    grouped_data_frames = {}\n",
    "    for group, dfs in data_frames.items():\n",
    "        if dfs:  # Check if the list of DataFrames is not empty\n",
    "            concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "            grouped_data_frames[group] = concatenated_df\n",
    "            # Save DataFrame to CSV\n",
    "            csv_file_path = os.path.join(base_folder, f'{group}.csv')\n",
    "            concatenated_df.to_csv(csv_file_path, index=False)\n",
    "            print(f'Saved {group} DataFrame to {csv_file_path}')\n",
    "\n",
    "    return grouped_data_frames\n",
    "\n",
    "# Example usage\n",
    "base_folder = r'F:\\daneshkar\\project1\\extracted_rar_files'\n",
    "start_date = 20240501\n",
    "end_date = 20240531\n",
    "folders_in_row = (\n",
    "    'raw_match_parquet',\n",
    "    'raw_odds_parquet',\n",
    "    'raw_point_by_point_parquet',\n",
    "    'raw_statistics_parquet',\n",
    "    'raw_tennis_power_parquet',\n",
    "    'raw_votes_parquet'\n",
    ")\n",
    "\n",
    "grouped_data_frames = read_and_group_parquet_files(base_folder, start_date, end_date, folders_in_row)\n",
    "\n",
    "# Display the groups and their DataFrames\n",
    "for group_name, df in grouped_data_frames.items():\n",
    "    print(f'Group: {group_name}')\n",
    "    # print(df.head())  # Print the first few rows of each DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and group names\n",
    "base_folder = r'F:\\daneshkar\\project1\\extracted_rar_files'\n",
    "group_names = [\n",
    "    'home_team_score',\n",
    "    'home_team',\n",
    "    'away_team',\n",
    "    'away_team_score',\n",
    "    'event',\n",
    "    'round',\n",
    "    'season',\n",
    "    'time',\n",
    "    'tournament',\n",
    "    'venue',\n",
    "    'odds',\n",
    "    'pbp',\n",
    "    'statistics',\n",
    "    'power',\n",
    "    'votes'\n",
    "]\n",
    "\n",
    "# Initialize a dictionary to store the DataFrames\n",
    "grouped_data_frames = {}\n",
    "\n",
    "# Read each CSV file into a DataFrame and store it in the dictionary\n",
    "for group_name in group_names:\n",
    "    csv_file_path = os.path.join(base_folder, f'{group_name}.csv')\n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        grouped_data_frames[group_name] = df\n",
    "        print(f'Successfully read {group_name}.csv')\n",
    "    else:\n",
    "        print(f'File {group_name}.csv not found')\n",
    "\n",
    "# Display the DataFrames (or perform further operations)\n",
    "for group_name, df in grouped_data_frames.items():\n",
    "    print(f'Group: {group_name}')\n",
    "    # print(df.head())  # Print the first few rows of each DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the shape of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of each DataFrame\n",
    "for group_name, df in grouped_data_frames.items():\n",
    "    print(f'Group: {group_name}, Shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many tennis players are included in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_players(grouped_data_frames):\n",
    "    player_ids = set()\n",
    "    \n",
    "    # Extract player IDs from home team info\n",
    "    if 'home_team' in grouped_data_frames:\n",
    "        home_team_df = grouped_data_frames['home_team']\n",
    "        if 'player_id' in home_team_df.columns:\n",
    "            player_ids.update(home_team_df['player_id'].unique())\n",
    "    \n",
    "    # Extract player IDs from away team info\n",
    "    if 'away_team' in grouped_data_frames:\n",
    "        away_team_df = grouped_data_frames['away_team']\n",
    "        if 'player_id' in away_team_df.columns:\n",
    "            player_ids.update(away_team_df['player_id'].unique())\n",
    "    \n",
    "    # Return the count of unique player IDs\n",
    "    return len(player_ids)\n",
    "\n",
    "# Count unique players\n",
    "num_unique_players = count_unique_players(grouped_data_frames)\n",
    "print(f'The number of unique tennis players in the dataset is: {num_unique_players}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "otherway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = grouped_data_frames['event']\n",
    "home_team = grouped_data_frames['home_team']\n",
    "away_team = grouped_data_frames['away_team']\n",
    "\n",
    "# Combine home and away team info into one DataFrame\n",
    "players_info = pd.concat([\n",
    "    home_team[['player_id', 'full_name']],\n",
    "    away_team[['player_id', 'full_name']]\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "number_of_tennis_players=len(players_info)\n",
    "\n",
    "print(f'The number of unique tennis players in the dataset is: {number_of_tennis_players}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Which player has the highest number of wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming grouped_data_frames is your dictionary containing all the dataframes\n",
    "event = grouped_data_frames['event']\n",
    "home_team = grouped_data_frames['home_team']\n",
    "away_team = grouped_data_frames['away_team']\n",
    "\n",
    "# Combine home and away team info into one DataFrame\n",
    "players_info = pd.concat([\n",
    "    home_team[['player_id', 'full_name']],\n",
    "    away_team[['player_id', 'full_name']]\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Merge event DataFrame with home_team and away_team DataFrames to get player IDs\n",
    "event = event.merge(home_team[['match_id', 'player_id']], left_on='match_id', right_on='match_id', how='left', suffixes=('', '_home'))\n",
    "event = event.rename(columns={'player_id': 'player_id_home'})  # Rename the merged column from home_team\n",
    "event = event.merge(away_team[['match_id', 'player_id']], left_on='match_id', right_on='match_id', how='left', suffixes=('', '_away'))\n",
    "event = event.rename(columns={'player_id': 'player_id_away'})  # Rename the merged column from away_team\n",
    "\n",
    "\n",
    "\n",
    "# Map winner_code to actual player IDs\n",
    "def get_winner_player_id(row):\n",
    "    if row['winner_code'] == 1:\n",
    "        return row['player_id_home']\n",
    "    elif row['winner_code'] == 2:\n",
    "        return row['player_id_away']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Check if 'player_id_home' and 'player_id_away' columns are present\n",
    "if 'player_id_home' in event.columns and 'player_id_away' in event.columns:\n",
    "    event['winner_player_id'] = event.apply(get_winner_player_id, axis=1)\n",
    "else:\n",
    "    raise KeyError(\"Expected columns 'player_id_home' and 'player_id_away' not found in the event DataFrame.\")\n",
    "\n",
    "# Count the number of wins for each player using groupby\n",
    "win_counts = event.groupby('winner_player_id').size().reset_index(name='win_count').rename(columns={'winner_player_id': 'player_id'})\n",
    "\n",
    "print(\"Win Counts DataFrame:\")\n",
    "print(win_counts)\n",
    "\n",
    "# Merge win counts with player information\n",
    "player_wins = pd.merge(win_counts, players_info, on='player_id', how='left')\n",
    "\n",
    "print(\"Player Wins DataFrame:\")\n",
    "print(player_wins)\n",
    "\n",
    "# Find the player with the highest number of wins\n",
    "if not player_wins.empty:\n",
    "    top_player = player_wins.loc[player_wins['win_count'].idxmax()]\n",
    "    print(f\"Player with the highest number of wins: {top_player['full_name']} with {top_player['win_count']} wins\")\n",
    "else:\n",
    "    print(\"No wins found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.How many sets are typically played in a tennis match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team_score_df = grouped_data_frames['home_team_score']\n",
    "# Select columns period_1 to period_5\n",
    "period_columns = ['period_1', 'period_2', 'period_3', 'period_4', 'period_5']\n",
    "\n",
    "# Count non-null values across rows (axis=1)\n",
    "home_team_score_df['filled_columns_count'] = home_team_score_df[period_columns].count(axis=1)\n",
    "\n",
    "# Find the mode of filled_sets_count\n",
    "mode_sets_count = home_team_score_df['filled_columns_count'].mode().values[0]\n",
    "\n",
    "print(f\"Typically, {mode_sets_count} sets are played in a tennis match.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
